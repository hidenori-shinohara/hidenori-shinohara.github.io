---
layout: post
title:  "FHE notes"
date:   2023-08-01
author: Hidenori
---

Notes from [this blog article](https://web.archive.org/web/20221207103926/https://blog.quarkslab.com/a-brief-survey-of-fully-homomorphic-encryption-computing-on-encrypted-data.html)

# Limits of FHE

Data dependent branching is an extremely complex topic in FHE.
Consider this simple algorithm:

```
def f(flag, a ,b):
    if flag:
        return a
    else:
        return b
```

If `flag`, `a`, and `b` are all given in cypher texts, then I can't return the correct value as I won't be able to decipher `flag`.
One possible approach is to do a calculation like `flag * a + (1 - flag) * b` where `flag` is assumed to be either 0 or 1.
This gives a mathematically correct answer, but this is computationally different.

To make it more obvious, look at this example:

```
def f(flag, a ,b):
    if flag:
        return super_expensive_function_1(a)
    else:
        return super_expensive_function_2(b)
```

If we returned `flag * super_expensive_function_1(a) + (1 - flag) * super_expensive_function_2(b)`, we will likely perform both expensive functions.
However, conventional programming languages will evaluate only one of them.

Another example is a conditional loop.
It is not obvious at all how one could make a conditional loop possible work with FHE.


# Lattice
Let $n$ be a natural number.
Let $v_1, \cdots, v_n \in \mathbb{R}^n$ such that $\\{ v_1, \cdots, v_n \\}$ forms a basis of $\mathbb{R}^n$.
We call $\\{ \sum c_i v_i \mid c_i \in \mathbb{Z} \\}$ a _lattice_.


# Closest Vector Problem
Consider a lattice $L$ formed by $v_1, \cdots, v_n$.
Let $x = (x_1, \cdots, x_n) \in \mathbb{Z}^n \setminus L$.
Then the problem of finding $v \in L$ such that $\abs{v - x} \leq \abs{v' - x}$ for all $v' \in L$ is called the _closest vector problem_.

# Shortest Vector Problem
Consider a lattice $L$ formed by $v_1, \cdots, v_n$.
Let $s = \min \\{ \abs{v} \mid v \ne 0 \in L \\}$.
Then the problem of finding a $v \in L$ such that $\abs{v} = s$ is called the shortest vector problem.

A shortest vector always exists.
Proof: For any nonzero vector in $L$, there are finitely many shorter vectors in $L$ as each vector has only integer coefficients.

# Learning with Error
Consider a lattice $L$ formed by $v_1, \cdots, v_n$.
Let $R^n$ be the vector space for which $L$ is a subspace.
Suppose that $v_1, \cdots, v_n$ are sufficiently large.

I will flip a coin and give you one vector.
- If heads, then I'll pick a random vector $v \in L$ and pick a sufficiently small error $e \in R^n$ and give you $v + e$.
- If tails, then I'll give you a random vector $R^n$.

The problem of figuring out which vector I gave  you is called the LWE problem.
It is easy to see that a solution to CVP will solve this problem efficiently.


# Reduction from CVP to SVP
TODO


# Basis Reduction Problem
Given a lattice $L$ spanned by $v_1, \cdots, v_n$, find a basis that is:
1. as orthogonal as possible, and
1. as short as possible.

We will not define this super rigorously.
A widely used solution is called LLL.


# Key generation

From here, we will calculate inner products and products of matrices.
To avoid confusion:
1. We will assume any vector of length $n$ is a column vector, and we take the transpose to get the row vector.
1. We will write $v_1^Tv_2$ when calculating the dot product $v_1 \cdot v_2$.
1. Let $u_1$ be the first standard basis column vector $(1, 0, \cdots, 0)$.

Furthermore, we assume that taking the modulo of an integer by a prime $q$ maps the value into $(-q / 2, q / 2]$.

Now the actual key generation is done as following:
1. Randomly pick $A \in \mathbb{Z}^{n \times n}_q$.
1. Randomly pick $s \in \mathbb{Z}^{n}_q$.
1. Sample $e$ from $N^n$.
1. Set $b = (As + pe) \mod q$.
1. Return $(A, b)$.

Notes:
- $p$ and $q$ are prime such that $p \ll q$.
- $e$ is the small error that we're introducing.
  We multiply it by $p$, so we can take modulo $p$ later to remove the error.
  Note that $p \ll q$ and $e$ is drawn from the normal distribution, so $pe$ is "small".
- $A$ is a random square matrix, and it doesn't have any other special property.
- $s$ is the private key that we don't publish.

# Encrypt

1. Let $m_1 \in \mathbb{Z}_p$ be the message and $(A, b)$ be the public key.
1. Sample $r_1$ from $N^n$.
1. Sample $e_1$ from $N^n$.
1. Let $a_1 = A^T \cdot r_1 \pmod q$.
1. Let $b_1 = (u_1b^Tr_1 + m_1u_1 + pe_1) \pmod q$.
1. Return $c_1 = (a_1, b_1)$.

# Decrypt

$((b_1 - u_1a_1^T s) \pmod q) \pmod p$ is $m_1u_1$.


# Proof that encryption and decryption work

$$
\begin{align*}
    b_1 - u_1 a_1^T s
        &\equiv u_1b^Tr_1 + m_1 u_1 + pe_1 - u_1 a_1^T s \\
        &\equiv u_1b^Tr_1 + m_1 u_1 + pe_1 - u_1 (A^T r_1)^T s \\
        &\equiv u_1b^Tr_1 + m_1 u_1 + pe_1 - u_1 r_1^T A s \\
        &\equiv u_1(As + pe)^Tr_1 + m_1 u_1 + pe_1 - u_1 r_1^T A s \\
        &\equiv u_1(s^T A^T r_1 + pe^T r_1) + m_1 u_1 + pe_1 - u_1 r_1^T A s \\
        &\equiv u_1s^T A^T r_1 + u_1pe^T r_1 + m_1 u_1 + pe_1 - u_1 r_1^T A s \\
        &\equiv u_1pe^T r_1 + m_1 u_1 + pe_1 \mod q.
\end{align*}
$$

Note that we didn't do any modulo reduction.
We assume that most terms are well within the range $(-q / 2, q / 2]$.
Some values in $As$ likely go over that range, but any terms containing $As$ cancel each other out.
It is important that the error terms are well within the range $(-q / 2, q / 2]$.
This is because $((x \pmod q) \pmod p) \not\equiv (x \pmod p)$ in general if $x \not\in (-q / 2, q / 2]$.
For instance, $x = 20, q = 13, p = 3$.
Then $((20 \pmod {13}) \pmod 3) \equiv 1 \not\equiv 2 \equiv (20 \pmod 3)$.


$u_1s^T A^T r_1 = u_1 r_1^T A s$ since we are just taking the transpose of a $1 \times 1$ matrix.
Finally, it is easy to see that taking modulo $p$ removes the two unnecessary terms and we obtain $m_1 u_1$.

# Addition

Let $c_1 = (a_1, b_1), c_2 = (a_2, b_2)$ be given.
Then $c_3 = (a_3, b_3)$ is simply $(a_1 + a_2, b_1 + b_2)$.

Then decryption works as expected as

$$
\begin{align*}
    (b_3 - u_1a_3^T s)
        &\equiv ((b_1 + b_2) - u_1(a_1 + a_2)^Ts) \\
        &\equiv (b_1 - u_1a_1^Ts) + (b_2 - u_1a_2^Ts) \\
        &\equiv (u_1pe^T r_1 + m_1 u_1 + pe_1) + (u_1pe^T r_2 + m_2 u_1 + pe_2) \\
        &\equiv u_1pe^T(r_1 + r_2) + (m_1 + m_2)u_1 + p(e_1 + e_2) \mod q.
\end{align*}
$$

Notice that it is crucial that neither $pe^T(r_1 + r_2)$ nor $p(e_1 + e_2)$ contain any values that go beyond the range $(-q / 2, q / 2]$.
This is because $((x \pmod q) \pmod p) \not\equiv (x \pmod p)$ in general if $x \not\in (-q / 2, q / 2]$.


In the original article, it uses the same $r$ for each cyphertext, but I assume that we use a different $r$ each time we encrypt a message.

# Transforming messages vs adding noises to messages

The article says:

> A key difference between classic cryptography and our schemes is that we do not transform our messages, we simply add noise until messages and noises are not distinguishable.

Now, this becomes fairly apparent.

Many other cryptographic schemes transform messages.
For instance, in RSA, one would take a power of the message.
However, as you can see, in this cryptographic scheme, we simply added noises.
More specifically, we added $(u_1b^Tr_1 + pe_1) \pmod q$ to $m_1u_1$.

# Size of ciphertext sizes

We assume that a message is in $\mathbb{Z}_p$ and a ciphertext is in $\mathbb{Z}_q^n$.
This means the ciphertext is at least $n$ times larger than the original message.
Furthermore, $p \ll q$, so the number of bits required to represent $q$ is likely significantly larger than that of $p$.


